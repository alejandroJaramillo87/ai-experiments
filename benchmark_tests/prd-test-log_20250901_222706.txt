[1m[33müßπ Pre-test Cleanup[0m
[1m[34müè≠ Production Test Mode[0m
==========================
[32müéØ Full 26k+ test suite capability with comprehensive resource management[0m
[36müí° Optimized for production deployment validation[0m

2025-09-01 22:27:06,407 - INFO - Initializing test mode: production
2025-09-01 22:27:06,456 - INFO - Backend detected: llamacpp
2025-09-01 22:27:06,456 - INFO - Concurrency adjusted to: 1
2025-09-01 22:27:06,456 - INFO - Test mode initialized: production
2025-09-01 22:27:06,456 - INFO - Configuration: Production deployment testing with comprehensive unit and integration coverage
2025-09-01 22:27:06,456 - INFO - Executing command: python -m pytest --tb=short --strict-markers --disable-warnings -q --cov=evaluator --cov=core --cov-report=term-missing --cov-fail-under=80 --cov-config=.coveragerc tests/unit tests/integration
........................................................................ [  9%]
........................................................sss............. [ 18%]
........................................................................ [ 28%]
........................................................................ [ 37%]
........................................................................ [ 46%]
........................................................................ [ 56%]
........................................................................ [ 65%]
........................................................................ [ 74%]
........................................................................ [ 84%]
........................................................................ [ 93%]
.................................................
ERROR: Coverage failure: total of 57 is less than fail-under=80
                                                                         [100%]
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.11-final-0 _______________

Name                                                             Stmts   Miss  Cover   Missing
----------------------------------------------------------------------------------------------
core/benchmarking_engine.py                                        247    115    53%   140-175, 187-188, 200-201, 211-251, 371-412, 447, 461-491, 496-536, 541-559, 562
core/calibration_engine.py                                         241    193    20%   103-112, 117-209, 213-224, 230-252, 262-314, 324-351, 363-434, 439-471, 475-486, 489
core/cognitive_evaluation_pipeline.py                              267     57    79%   30-32, 37-39, 44-46, 51-53, 131-132, 138-139, 145-146, 152-153, 195-197, 269-271, 291-293, 309-311, 335-337, 349-350, 353-356, 369, 376, 418-430, 448, 456, 496, 504
core/cognitive_validation.py                                       231    231     0%   17-453
core/production_calibration.py                                     277    228    18%   69-89, 93-104, 108-155, 159-168, 172-225, 240-263, 267-281, 287-307, 317-325, 335, 345-358, 362-415, 420-514, 518-521, 527
core/resource_manager.py                                           195    195     0%   18-377
core/results_manager.py                                            246     42    83%   167-177, 253, 260-261, 302, 324, 365-378, 400, 405-406, 423-430, 437-438, 447-448, 483-519, 526, 535-541
core/test_mode_config.py                                           166      8    95%   314, 318, 322, 327, 346, 349, 358, 386
evaluator/__init__.py                                                8      0   100%
evaluator/advanced/__init__.py                                       6      0   100%
evaluator/advanced/consistency_validator.py                        315     98    69%   32-34, 41-43, 112-114, 222-245, 250, 255, 273-275, 279-294, 316, 321-324, 332, 360, 369-390, 400, 407-408, 413, 498, 505, 553, 573, 592, 604, 632-664, 687-694
evaluator/advanced/context_analyzer.py                             545    120    78%   25-27, 33-35, 41-43, 78, 120-122, 136, 144-146, 179-181, 194, 229-231, 270-277, 284-286, 299, 319, 337-339, 386-388, 395, 413-416, 421-432, 487-488, 508, 527, 576, 593-602, 611, 706-707, 776, 860-891, 898, 902, 909, 917-922, 933, 951, 969, 975-977, 997, 1057, 1087-1088, 1094-1095, 1128-1132, 1158-1183, 1187-1190
evaluator/advanced/entropy_calculator.py                           371     77    79%   25-27, 33-35, 41-43, 149-161, 183, 197-198, 228, 232, 261, 278-280, 294, 300-303, 315, 340, 382, 468-510, 659-660, 686, 744-768, 773-776
evaluator/advanced/model_loader.py                                  80     24    70%   21-22, 46, 49, 77, 85-90, 138-139, 151-152, 165-179, 196-199, 210-211, 216
evaluator/advanced/quantization_tester.py                          532     55    90%   88-90, 138-140, 154, 202-204, 217, 248-250, 420-421, 550-551, 559, 599-602, 688, 695, 761, 801, 892-893, 896-897, 909, 911, 923-924, 927-928, 1027, 1108, 1199, 1213, 1354, 1399-1421, 1425-1428
evaluator/advanced/semantic_coherence.py                           698    240    66%   26-28, 35-37, 44-46, 87, 91-93, 106-123, 150-154, 166-182, 190-194, 226, 230-232, 247, 265, 268, 272-274, 288, 304, 309-313, 326, 349-351, 364, 412-414, 464-466, 707, 719-787, 793, 802-807, 831-833, 837-887, 892, 920-922, 933, 963-965, 969-1042, 1047, 1052-1076, 1147, 1168, 1193-1218, 1223, 1289-1291, 1311, 1407-1429, 1434-1437
evaluator/core/__init__.py                                           5      0   100%
evaluator/core/advanced_analysis_orchestrator.py                   319    108    66%   141, 185-188, 196-199, 207-210, 218-221, 229-232, 241-244, 253-256, 284-294, 306-311, 326, 358, 371-390, 414, 520, 531, 540, 570, 574, 585, 590-601, 610-618, 627-629, 638, 648-653, 662, 673, 720-721, 754, 758-773, 777-778, 782-783, 806-843
evaluator/core/domain_evaluator_base.py                            194     58    70%   55-58, 70, 93, 98, 116, 124-141, 147-161, 172, 175, 195, 204, 223-225, 255, 290, 297, 309, 314, 321, 339, 360, 364, 368-385
evaluator/core/ensemble_disagreement_detector.py                   230     61    73%   142-178, 195-209, 222, 276, 370, 468-505, 511-527, 531-548, 623
evaluator/core/evaluation_aggregator.py                            354     44    88%   149, 173, 197, 236, 244, 296, 304, 348, 352, 355, 373, 428, 467-469, 486, 492, 516, 534, 548-552, 559, 566, 587-588, 597-598, 649-650, 654, 668-717
evaluator/core/evaluation_config.py                                 20      0   100%
evaluator/cultural/__init__.py                                      10      0   100%
evaluator/cultural/community_leadership_evaluator.py               305    275    10%   45-237, 262, 266, 270, 287-306, 318-357, 369-407, 419-472, 484-530, 542-582, 594-632, 644-682, 694-740, 751-754, 765-806
evaluator/cultural/conflict_resolution_evaluator.py                250    221    12%   44-187, 212, 216, 220, 236-253, 265-305, 317-356, 368-414, 426-465, 477-515, 527-566, 578-617, 628-631, 642-671
evaluator/cultural/cross_cultural_coherence.py                     181      1    99%   196
evaluator/cultural/cultural_authenticity.py                        166      1    99%   171
evaluator/cultural/cultural_dataset_validator.py                   266     81    70%   120-121, 126, 134-148, 154-191, 195-206, 210-221, 225-247, 251-264, 268-269, 297-299, 342, 354, 360-362, 375-376, 422-429, 435, 450, 471-477, 487-512, 520-523, 545-546, 617-619
evaluator/cultural/cultural_pattern_library.py                     174      1    99%   397
evaluator/cultural/intercultural_competence_assessor.py            279    249    11%   45-224, 244, 248, 252, 269-288, 300-337, 349-389, 401-441, 453-493, 505-545, 557-597, 609-655, 667-699, 710-713, 724-754
evaluator/cultural/social_hierarchy_navigation_assessor.py         269    239    11%   45-216, 231, 235, 239, 256-275, 287-332, 344-389, 401-433, 445-477, 489-521, 533-565, 577-615, 627-663, 674-677, 688-724
evaluator/cultural/tradition_validator.py                          188      2    99%   181, 539
evaluator/data/__init__.py                                           3      0   100%
evaluator/data/domain_metadata_extractor.py                        414    221    47%   274, 276, 307-311, 334-335, 356, 370-374, 388-389, 391-392, 399-430, 510-511, 518-558, 568-588, 604-654, 675-714, 718-746, 750-783, 787-818, 826-835, 850-888, 904-924
evaluator/data/open_cultural_apis.py                               340    235    31%   78-89, 93-94, 99, 104, 112-150, 155-156, 160-175, 179-200, 204-218, 222, 235, 252-293, 297-298, 303-320, 324-339, 343-365, 369-379, 383, 396, 413-448, 452-453, 457-471, 475-502, 506-510, 514, 527, 606-668, 680-703, 707-710, 714-736, 743-784, 788-806
evaluator/linguistics/__init__.py                                    5      0   100%
evaluator/linguistics/historical_linguistics_evaluator.py          273    243    11%   45-182, 202, 206, 210, 227-246, 258-304, 316-349, 361-393, 405-437, 449-492, 504-545, 557-595, 607-647, 658-661, 672-702
evaluator/linguistics/multilingual_code_switching_evaluator.py     305    275    10%   43-189, 206, 210, 214, 231-250, 261-272, 277-326, 338-385, 397-429, 441-472, 484-538, 550-579, 591-614, 626-670, 684-694, 698-701, 712-745
evaluator/linguistics/pragmatic_meaning_evaluator.py               300    270    10%   45-223, 240, 244, 248, 265-284, 296-347, 359-408, 420-470, 482-520, 532-571, 583-621, 633-671, 683-722, 733-736, 747-781
evaluator/linguistics/rhythmic_analyzer.py                         230      6    97%   164, 174-175, 224-225, 439
evaluator/subjects/__init__.py                                       7      0   100%
evaluator/subjects/creativity_evaluator.py                         261     16    94%   150-151, 189-192, 335-336, 374-377, 432-435
evaluator/subjects/domain_evaluation_router.py                     289     41    86%   269, 277-284, 291, 299-306, 313, 321-328, 352-355, 360-361, 364-367, 372-373, 568, 570
evaluator/subjects/enhanced_universal_evaluator.py                 657    400    39%   152, 156, 163-169, 246, 261, 282, 296-311, 346, 403, 407-411, 442-457, 462-470, 502, 508, 515, 523-533, 539-588, 596-635, 639-662, 666-682, 686-704, 708-734, 743-754, 808-846, 850-867, 871-889, 893-911, 915-938, 948-956, 961-969, 974-982, 987-995, 1000-1008, 1013-1021, 1032-1037, 1041-1045, 1049-1055, 1059-1065, 1069-1077, 1081-1088, 1099, 1111, 1119-1121, 1132-1248, 1272-1274, 1283-1296, 1302, 1336-1375, 1391-1424, 1444, 1446, 1448, 1450, 1452, 1454, 1461-1462
evaluator/subjects/integration_evaluator.py                        272     25    91%   161, 163, 165, 167, 212-220, 227, 234, 276, 310-311, 363-366, 381, 396-397, 461-462
evaluator/subjects/language_evaluator.py                           343    310    10%   48-217, 241, 245, 249, 267-289, 301-349, 361-413, 425-485, 497-538, 550-591, 603-653, 665-699, 711-760, 772-828, 839-842, 853-883
evaluator/subjects/pattern_based_evaluator.py                      196     41    79%   208, 226, 266, 268, 270, 280-285, 304, 317-349, 390, 392, 396, 410, 427, 429, 436, 462, 482, 512-522
evaluator/subjects/reasoning_evaluator.py                         1299    334    74%   24-26, 31-33, 38-40, 45-47, 52-54, 58, 66-68, 73-75, 80-82, 207, 250-251, 297, 324, 332-338, 342, 400, 402, 404, 410, 412, 480-481, 522-527, 532-537, 542-547, 552-557, 565-566, 573-576, 585-586, 595-596, 605-606, 656-659, 704, 706, 737-803, 820, 824-827, 836, 840, 850-851, 859, 876, 878, 880, 882, 884, 886, 946-959, 966-970, 981, 993, 999-1000, 1036-1037, 1042, 1237-1239, 1665, 1698, 1751, 1761, 1763, 1767, 1769, 1773, 1826-1827, 1833-1834, 1847-1848, 1859-1860, 1874-1883, 1888-1919, 1949, 1951, 2032, 2037-2038, 2091, 2125, 2138, 2140, 2142, 2168-2169, 2180, 2197, 2199-2202, 2305, 2309, 2314, 2316, 2322, 2458, 2462, 2465, 2471, 2491, 2505, 2603-2640, 2654-2687, 2696-2736, 2740-2756, 2760-2792, 2796-2847, 2851-2889, 2899-2919, 2923-2936, 2940-2947
evaluator/subjects/social_evaluator.py                             372    326    12%   54-55, 59-65, 69, 73, 85, 91-109, 120, 145, 172, 199, 228, 263, 292, 334-374, 391-442, 454-510, 522-572, 584-640, 652-685, 697-747, 759-808, 819-850, 855-893, 897-912, 916-919, 930-965
evaluator/validation/__init__.py                                     7      0   100%
evaluator/validation/community_flagging_system.py                  261     28    89%   123-130, 146-147, 176-177, 323-332, 350-360, 381, 400, 403, 415-420, 527-528, 532, 607
evaluator/validation/integrated_validation_system.py               261    157    40%   76, 78, 85, 155-357, 382-398, 402-420, 424-439, 443-461, 468-494, 498-529, 533-577, 603, 608, 612-615, 619-622
evaluator/validation/knowledge_validator.py                        374     72    81%   32-34, 40-42, 131-133, 292-294, 311-339, 494, 503, 520-522, 526-540, 561-568, 609, 651, 662, 720-722, 736, 739-742, 751, 756, 761, 765-768, 824, 892
evaluator/validation/multi_source_fact_validator.py                315     78    75%   201-203, 211-212, 219-220, 228-229, 258, 271-273, 303, 316-318, 345, 360-362, 378-391, 396, 400, 420, 434, 452, 456, 466, 473-474, 478, 488, 494-495, 515, 523, 528, 546-550, 562-567, 581-584, 590, 602, 612, 618, 636, 667-696
evaluator/validation/validation_runner.py                          263    171    35%   63, 65, 169-203, 209-259, 274-308, 312-330, 334-352, 356-374, 378-398, 402-424, 428-456, 460-472, 489-513, 529-554, 558-573, 582-588, 592-612, 616-627, 631, 652, 656
evaluator/validation/wikipedia_fact_checker.py                     351    129    63%   130, 153-155, 197-235, 260-270, 279-293, 348-376, 380, 384-396, 400-419, 423-441, 448-449, 456-459, 467-478, 489-507, 517-518, 564, 619, 628, 636, 649, 653, 683, 694, 711-722
----------------------------------------------------------------------------------------------
TOTAL                                                            15033   6402    57%
FAIL Required test coverage of 80% not reached. Total coverage: 57.41%
766 passed, 3 skipped, 18 warnings in 340.88s (0:05:40)
‚öôÔ∏è Configuration:
   Mode: production
   Description: Production deployment testing with comprehensive unit and integration coverage
   Chunk Size: 25
   Max Concurrent: 1
   Timeout Per Test: 45s
   Memory Limit: 8000MB
   Coverage Enabled: True
   Verbose Output: False
   Include Functional: False
   Include Calibration: False

üöÄ Running production tests:
   Test Directories: tests/unit, tests/integration
   Pytest Args: --tb=short --strict-markers --disable-warnings -q --cov=evaluator --cov=core --cov-report=term-missing --cov-fail-under=80 --cov-config=.coveragerc

make[1]: Entering directory '/home/alejandro/workspace/ai-workstation/benchmark_tests'
[1m[33müßπ Post-test Cleanup[0m
make[1]: Leaving directory '/home/alejandro/workspace/ai-workstation/benchmark_tests'
make: *** [Makefile:872: test-production] Error 1
