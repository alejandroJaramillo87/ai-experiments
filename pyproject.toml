# pyproject.toml

[tool.poetry]
name = "ai-toolkit"
version = "0.1.0"
description = "Base Python project for AI engineering on RTX 5090"
authors = ["Alejandro <alejandroj1234@proton.me>"]
license = "MIT"
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = ">=3.12,<3.13" # Ensure you have Python 3.12 installed via pyenv

# Core AI/ML Frameworks and Utilities
torch = {version = ">=2.3.0,<3.0.0", source = "pytorch_cuda_cu128"} # Add this line for torch
torchvision = {version = ">=0.18.0,<1.0.0", source = "pytorch_cuda_cu128"} # Add this line for torchvision
torchaudio = {version = ">=2.3.0,<3.0.0", source = "pytorch_cuda_cu128"} # Add this line for torchaudio
transformers = ">=4.51.1,<4.52.0"
datasets = ">=3.1.0,<4.0.0"
accelerate = ">=1.8.1,<2.0.0"
peft = ">=0.15.2,<0.16.0"
evaluate = ">=0.4.4,<0.5.0"
deepspeed = ">=0.17.1,<0.18.0"
bitsandbytes = ">=0.46.0,<0.47.0"
sentencepiece = ">=0.2.0,<0.3.0"
einops = ">=0.8.1,<0.9.0"

# Model Management
huggingface-hub = ">=0.32.0,<0.33.0" 
hf-transfer = ">=0.1.8,<0.1.9"     

# Data Science & Visualization
jupyterlab = ">=4.4.3,<5.0.0"
matplotlib = ">=3.10.3,<4.0.0"
seaborn = ">=0.13.2,<0.14.0"
scikit-learn = ">=1.7.0,<2.0.0"
pandas = ">=2.3.0,<3.0.0"

# Experiment Tracking & MLOps
wandb = ">=0.20.1,<0.21.0"
mlflow = ">=3.1.1,<4.0.0"
tensorboard = ">=2.19.0,<3.0.0"

# General Utilities & Optimization
tqdm = ">=4.67.1,<5.0.0"
rich = ">=14.0.0,<15.0.0"
ray = { version = ">=2.47.1,<3.0.0", extras = ["default"] }
optuna = ">=4.4.0,<5.0.0"

# API Development
fastapi = ">=0.115.0,<0.116.0"
uvicorn = ">=0.34.3,<0.35.0"

# TensorRT-LLM Quantization Dependencies
tensorrt-llm = "0.20.0"
nemo-toolkit = ">=2.0.0,<2.3.2"
rouge-score = "^0.1.2"
transformers-stream-generator = "^0.0.5"
tiktoken = "^0.9.0"
mpmath = "^1.3.0"
requests = "^2.32.4"

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"

# Define the custom source for PyTorch
[[tool.poetry.source]]
name = "pytorch_cuda_cu128" # Give it a descriptive name
url = "https://download.pytorch.org/whl/cu128"
priority = "explicit" 

# Add NVIDIA PyPI source
#[[tool.poetry.source]]
#name = "nvidia"
#url = "https://pypi.nvidia.com"
#priority = "supplemental"

# Your primary PyPI source (should usually be last if you have supplemental ones)
[[tool.poetry.source]]
name = "pypi"
priority = "primary"

[tool.poetry.group.dev.dependencies]
pytest= ">=7.0.0"
pytest-asyncio = ">=0.21.0"
pytest-mock = ">=3.11.0"
black = ">=23.0.0"
ruff = ">=0.1.0"
mypy = ">=1.0.0"


[tool.black]
line-length = 88
target-version = ['py313']
include = '\.pyi?$'

[tool.ruff]
line-length = 88
target-version = "py313"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]
ignore = [
    "E501",  # line too long, handled by black
    "B008",  # do not perform function calls in argument defaults
    "W191",  # indentation contains tabs
    "W293",  # blank line contains whitespace
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]
"tests/*" = ["S101"]